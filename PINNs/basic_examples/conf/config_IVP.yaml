training:
  max_steps: 10000
  grad_agg_freq: 1
  rec_results_freq: 100000000
  rec_validation_freq: 100000000
  rec_inference_freq: 100000000
  rec_monitor_freq: 100000000
  rec_constraint_freq: 100000000 
  save_network_freq: 1000
  print_stats_freq: 100
  summary_freq: 1000
  grad_clip_max_norm: 0.5
  monitor_grad_clip: true
  ntk:
    use_ntk: false
    save_name: null
    run_freq: 1000
amp:
  enabled: false
  mode: per_order_scaler
  dtype: float16
  autocast_activation: false
  autocast_firstlayer: false
  default_max_scale_log2: 0
  custom_max_scales_log2: {}
graph:
  func_arch: false
  func_arch_allow_partial_hessian: true
stop_criterion:
  metric: null
  min_delta: null
  patience: 50000
  mode: min
  freq: 1000
  strict: false
profiler:
  profile: false
  start_step: 0
  end_step: 100
  name: nvtx
network_dir: .
initialization_network_dir: ''
save_filetypes: []
summary_histograms: 'off'
jit: false
jit_use_nvfuser: true
jit_arch_mode: only_activation
jit_autograd_nodes: false
cuda_graphs: false
cuda_graph_warmup: 20
find_unused_parameters: false
broadcast_buffers: false
device: ''
debug: false
run_mode: train
arch:
  fully_connected:
    arch_type: fully_connected
    input_keys: ???
    output_keys: ???
    detach_keys: ???
    scaling: null
    layer_size: 512
    nr_layers: 6
    skip_connections: false
    activation_fn: silu
    adaptive_activations: false
    weight_norm: true
models: ???
loss:
  _target_: physicsnemo.sym.loss.aggregator.Sum
  weights:
    interior: 1.0
    IC: 100.0
  ic_w: 100.0

optimizer:
  _params_:
    compute_gradients: adam_compute_gradients
    apply_gradients: adam_apply_gradients
  _target_: torch.optim.Adam
  lr: 0.001
  betas:
  - 0.9
  - 0.999
  eps: 1.0e-08
  weight_decay: 0.0
  amsgrad: false
scheduler:
  _target_: custom
  _name_: tf.ExponentialLR
  decay_rate: 1.0
  decay_steps: 4000
batch_size:
  Interior: ${data.N_R}
  IC: ${data.N_B}
custom: ???

train:
  mode: hybrid            # adam | lbfgs | hybrid
  adam:
    epochs: 25000
    lr: 1.0e-3
    log_interval: 200
  lbfgs:
    iters: 1000
    history: 10
    log_interval: 50


domain:
  t_min: 0.0
  t_max: 50.0

ode:
  a: 0.1
  b: 0.002
  c: 0.2
  d: 0.0025
  x0: 80.0
  y0: 20.0

data:
  N_R: 2000       # interior collocation
  N_B: 2          # IC 쪽만 사용(좌 경계). 저장 크래시 회피를 위해 코드에서 max(2, N_B)로 처리
  N_test: 501     # 평가/플롯 포인트 수

model:
  hidden_dim: 50
  hidden_layers: 4
  out_dim: 2
  use_fourier: true   # 시간축 RFF 사용 여부

fourier:
  mapping_size: 10
  scale: 3.0